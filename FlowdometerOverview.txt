FlowdometerOverview.txt

End User Setup Documentation
  https://raw.githubusercontent.com/michaelmuse/Flowdometer/master/README.md


Flows

  Flow 1 (Flowdometer - Listener Tracking Trigger):
    Latest code: https://gist.githubusercontent.com/michaelmuse/0bb5a6600c34799382b42c1998e9fbf9/raw/48ec3cb2a762beabc1470e6787ed06ca83576fc9/Listener_Batch_Flow.flow-meta.xml
    Name: Flowdometer - (1) Listener Tracking Trigger
      Description: Flowdometer handler for setting up listeners for your object and field.
      Trigger Conditions
        Object: Listener__c
        Trigger Type: Record After Save
        Record Trigger Type: Create and Update
        Additional Filters: isActive__c should be equal to true
      Elements
        Decision Element: "Check If the Flow is Active"
        Checks if Flowdometer__isActive__c field on the record is true.
        If true, moves to assignment element.
        Assignment Element: "FlowdoConfig Value Assignment"
        Assigns the current record to a variable varFlowdoConfig.
        Sub-Flow: "Listener Config Main Flow"
        Takes the varFlowdoConfig as an input argument.
        Scheduled Paths
        Run Every 3 Minutes: The flow runs every 3 minutes, depending on the Last_Check__c field of the record.
      Context of Loops and DMLs
        Loops: No loops detected.
        DML Operations: No explicit DML operations detected, but the sub-flow "Listener Config Main Flow" may have DML operations (we can't tell from this XML alone).
      Efficiency and Bulkification
        Efficiency: As far as we can tell from this XML, the flow seems relatively straightforward. It doesn't contain any loops or DML operations, which are usually the key factors affecting bulkification.
        Bulkification: Since the flow triggers after record creation and update, and it doesn't show any DML or loop operations, it should generally be bulk-safe. However, the sub-flow might be a point of concern for bulkification.

  Flow 2 (Flowdometer - Listener Finds Changed Records):
    Latest code: https://gist.githubusercontent.com/michaelmuse/8bd43794f17e72112704184ee04ddd7b/raw/b7b003785033b8a581d60acaafe51e460f9c0635/Listener_Configuration_Main_Flow.flow-meta.xml
      Name: Flowdometer - (2) Listener Finds Changed Records
        Description:
        Triggered by: Flowdometer - Listener Tracking Trigger. Flowdometer handler to query for untracked changes.
        Trigger Conditions: This appears to be an AutoLaunched Flow, likely called from another flow or process.
        Elements
          Decision Element: "Check FlowdoConfig"
            Checks if varFlowDoConfig.isActive__c is true.
            If true, moves to record lookup.
          Record Lookup: "Get ALL Record Types"
            Queries for specific RecordType objects.
            Decision Element: "Found Record Types?"
            Checks if any records were found in the previous step.
          New: Apex Action: "Sort by Record Type"
            Calls an Apex action to sort records by their Record Type.
          Apex Action: "Query and Parse History Records Latest"
            Calls an Apex action ListenerFlowController and passes varFlowDoConfig as an input parameter.
          Decision Element: "Check Records"
            Checks the output from the Apex action to see if there are records (hasRecords) and if the check was successful (checkSuccess).
          Loop: "Loop Through Parsed Records"
            Iterates through lstListenerFlow.
          Sub-Flow: "Create Tracker Records Using Parsed History Records"
            Called within the loop to process each record.
          Assignment Elements:
            Multiple assignment elements to handle error messages and update Last_Check__c and Last_Execution_On__c.
          Record Update: "Update FlowdoConfig"
            Updates the Listener__c record.
        Context of Loops and DMLs
          Loops: One loop, "Loop Through Parsed Records," iterating through lstListenerFlow.
          DML Operations: Two explicit record update operations, plus the DMLs that might be in the sub-flow and Apex action.
        Efficiency and Bulkification
          Efficiency: This flow is more complex than the first one and includes Apex actions for sorting, loops, and multiple decision and assignment elements.
         Bulkification: The flow contains a loop and multiple DML operations, which could be points of concern for bulkification.

  Flow 3 (Flowdometer - Listener Creates Trackers):
    Latest code: https://gist.githubusercontent.com/michaelmuse/0cb1f81bb578cc10cd4f9c0189cc1793/raw/9617ea11496613561986f413c8f4d0771808adce/Listener_Flow_Sub_Flow.flow-meta.xml
    Name: Flowdometer - (3) Listener Creates Trackers 
      Description: This flow is used to create Flow and Step records for the record being tracked, using history records collected in the Flowdometer - (2) Listener Finds Changed Records flow.
      Triggered By: This is an AutoLaunched Flow, likely called from another flow or process.
      Elements:
        Record Lookups: There are three record lookup elements that query for specific Flow__c and Step__c objects based on certain conditions.
        Decisions: There are multiple decision elements that check for the existence of Flows, Steps, and specific record types. They also check if certain records were found and decide the next steps based on these conditions.
        Apex Actions: There is one Apex action that calls the ListenerUpdateFlowController and passes various parameters as input.
        Assignments: Multiple assignment elements are used to set error messages, set up Flow Tracker, set Goal Flow, set Tracker Flow, set Goal ID, set Latest Tracker Step, and more.
        Sub-Flows: There are no sub-flows in this flow.
        Loops: There are three loops that iterate through the Get_ALL_Steps and varALLFlows collections and sort and assign flows.
        Record Creates: Two record creates elements are used to create Flow Tracker and Step.
        Record Updates: Multiple record updates are used to add error messages to the Listener, update Flow, and update Last Step.
      Context of Loops and DMLs: Loops: Three loops, iterating through Get_ALL_Steps, varALLFlows and Sort_and_Assign_Flows. DML Operations: Two explicit record create operations and multiple record update operations.
      Efficiency and Bulkification: Efficiency: This flow is complex with multiple decision, assignment, record lookup, record create, record update elements and loops. Bulkification: The flow contains multiple loops and DML operations which could be points of concern for bulkification.


Apex
  All Method signatures in my apex files:
    https://gist.githubusercontent.com/michaelmuse/c29b1571124939fa60fc0b26df14bba2/raw/acfd932c08c7eaa82cad03f44088426977e1649b/FlowdometerApexMethodSignatures.json
  ListenerFlowController.cls
    Latest code: https://gist.githubusercontent.com/michaelmuse/cb4df0a6a0c1cbf630e81cf28c70000f/raw/fc2f1c06093cab32555b00b60ea2e818d2df56b3/ListenerFlowController.cls
    Extensive summary of this controller in the comments at the beginning of the code
    Main Invocable Action: Query & Parse History Records
    Used by Flow 2
  ListenerFlowControllerTest.cls
    Latest code: https://gist.githubusercontent.com/michaelmuse/6908a3176b423bee76b216ab33948492/raw/c2e1bbfeaccaaccfaac00583a5f97d78158f9877/ListenerFlowControllerTest.cls
    Tests our controller, ListenerFlowController.cls
  TestDataFactory.cls
    Latest code: https://gist.githubusercontent.com/michaelmuse/6ff9d325ef68cf17d3c0688fc4461a1a/raw/92eb92bc3342a28a3bf401372075551b85a4e9d6/TestDataFactory.cls
    Builds data for ListenerFlowControllerTest.cls
  ListenerUpdateFlowController.cls
    Main Invocable Action: Update Flow Records
    Used by Flow 3
    Defined in ListenerUpdateFlowController.cls

Data Model
  https://gist.githubusercontent.com/michaelmuse/ef3ccbd0692b0c633f5428168442dd9f/raw/6307d878ee2af66961616bc658f25d1fbce03520/gist_content.json

Refactor
  DML Considerations
      At the moment, Flow 2 is looping over and calling our Apex invocable method in ListenerFlowController.cls
      In Flow 3, the given record will cause 3, 4, or 5 DML transactions...
      I’m concerned that if we successfully query a lot historical records on the first run, we'll hit loop, DML, or governor limits
  Plan for refactor of existing data
    To avoid potential DML errors while processing the historical records...
    I’m considering refactoring Flow 2 to create batches of records to send to Flow 3
    Flow 3 would then be refactored to receive these batches, and have a new loop at the beginning to iterate over them.
    I'd need to make sure to store all records to be created in a batch inside of collections, and then upload the full collection in a single DML. Same for the records to update.
    One consideration is that I really need to make sure that when we do the update, all the creates have finished, because on update...
    I need to reference the created records.
  Other ideas:
    Adding a long texgt field on listener, handling one batch and putting the rest of the unhandled records into this field, updating the record, then adding a zero minute schedule..
    To process the next batch, from this field, instead of running a query for them.
  Some ideas I don't think I'll do:
    Move Flow 1 and 2 together, and then move flow 1 to always be scheduled for zero minutes, grabbing anything that can be processed and processing it, then updating a custom metadata to iterate my batches, resetting it at the end of the whole batch being processed, keeping every three minutes too?
    Using platform events for the last 3 DMLs - Update step, apex update listener, flow update listener


Question: do you think this is feasible? If so, what batch size would I want to put into Flow 3? And what's the total number of records I can fetch in Flow 2?
Answer: Yes, here's how:
  Limit-Constrained Operations Overview
  Let's break down the governor limit-sensitive operations based on your overview.

  Flow 1: Doesn't seem to have any explicit DML or SOQL operations, although it calls a sub-flow which might have them.
  Flow 2:
    Loops: 1
    DML Operations: 2 explicit (plus potential ones in sub-flows and Apex actions)
    SOQL Queries: 1 (Get ALL Record Types)
  Flow 3:
    Loops: 3
    DML Operations: Multiple (at least 2 creates and multiple updates)
    SOQL Queries: 3 (based on record lookups)
    Apex:
  Invocable methods in ListenerFlowController.cls and ListenerUpdateFlowController.cls could potentially have DML/SOQL operations, but they are not explicitly mentioned.
  Salesforce Governor Limits
    Here are some of the relevant Salesforce governor limits as of my last update in January 2022:
      Maximum SOQL queries: 100
      Maximum DML statements: 150
      Maximum CPU time: 10,000 ms
      Maximum heap size: 6 MB
      Maximum number of records retrieved by SOQL queries: 50,000
      Maximum number of records processed by DML: 10,000
    Educated Guess on Batch Sizes and Record Limits
      Flow 3 - Batch Size
        For Flow 3, each batch would require:
          At least 3 loops
          Multiple DML operations (let's assume 5 for simplicity)
        Let's say you set the batch size to N for Flow 3. Then, within each transaction, you would have:
          3×N loop iterations
          5×N DML operations
        To stay within the governor limits, you could use:
          N×3<100(for SOQL)
          N×5<150(for DML)
        Solving these would give you 
          N<33 and N<30, respectively. 
        To be on the safe side, you might consider a batch size of around 25-30 records for Flow 3.
      Flow 2 - Total Records
        If Flow 3 can safely handle a batch size of 25-30, then Flow 2 should aim to fetch records in multiples of this batch size.
        A safe bet would be around 1000-1200 total records (given that you will divide these into batches of 25-30 records each to send to Flow 3).
        This would ensure that you don't run into SOQL query limits (50,000 records) or heap size limits.
      Trade-offs
        Smaller batch sizes are safer but may require more API calls and could be slower.
        Larger batch sizes are faster but risk hitting governor limits.
